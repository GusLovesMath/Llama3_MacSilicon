# Meta-Llama-3 on Mac Silicon

## Overview
This Jupyter notebook demonstrates how to run the Meta-Llama-3 model on Apple's Mac silicon devices. It includes examples of generating responses from simple prompts and delves into more complex scenarios like solving mathematical problems.

## Requirements
- Apple Mac with M1, M2, or M3 chip
- macOS Monterey or later
- Python 3.x
- Required Python packages: `ipywidgets`, `torch`, `mlx-lm`

## Setup
Clone this repository and install the necessary packages:

```bash
pip install ipywidgets torch mlx-lm
```

[MLX Cummunity on Hugging Face](https://huggingface.co/mlx-community)
